{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05800a79-b80a-4804-a802-680f41f804fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cb3f258-7bde-40d5-93b9-dfa4b2fd8788",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asia\\.conda\\envs\\py312tf9\\Lib\\site-packages\\transformers\\configuration_utils.py:312: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Wav2Vec2Model(\n",
       "  (feature_extractor): Wav2Vec2FeatureEncoder(\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): Wav2Vec2GroupNormConvLayer(\n",
       "        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "        (activation): GELUActivation()\n",
       "        (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (feature_projection): Wav2Vec2FeatureProjection(\n",
       "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): Wav2Vec2Encoder(\n",
       "    (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "      (conv): ParametrizedConv1d(\n",
       "        768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
       "        (parametrizations): ModuleDict(\n",
       "          (weight): ParametrizationList(\n",
       "            (0): _WeightNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (padding): Wav2Vec2SamePadLayer()\n",
       "      (activation): GELUActivation()\n",
       "    )\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x Wav2Vec2EncoderLayer(\n",
       "        (attention): Wav2Vec2SdpaAttention(\n",
       "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Wav2Vec2FeedForward(\n",
       "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 준비\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c115e4b6-6d81-45e4-8877-2cc78da52732",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"aihub_emotion_preprocessed_cleaned.csv\")\n",
    "df = df[df[\"final_emotion\"] != \"disgust\"]\n",
    "\n",
    "audio_dirs = ['./감정 분류를 위한 대화 음성 데이터셋/4차년도', './감정 분류를 위한 대화 음성 데이터셋/5차년도', './감정 분류를 위한 대화 음성 데이터셋/5차년도_2차']\n",
    "def find_existing_audio_path(wav_id):\n",
    "    for d in audio_dirs:\n",
    "        path = os.path.join(d, wav_id + \".wav\")\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "    return None  # 어떤 폴더에도 없으면 None\n",
    "df[\"file_path\"] = df[\"wav_id\"].apply(find_existing_audio_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9254be2-7ad7-4142-8e53-4ffd59f43338",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"file_exist\"] == True].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb65c8f2-b292-47ae-8005-1721fa00075a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13921 entries, 0 to 13920\n",
      "Data columns (total 19 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   wav_id         13921 non-null  object\n",
      " 1   발화문            13921 non-null  object\n",
      " 2   final_emotion  13921 non-null  object\n",
      " 3   1번 감정          13921 non-null  object\n",
      " 4   1번 감정세기        13921 non-null  int64 \n",
      " 5   2번 감정          13921 non-null  object\n",
      " 6   2번 감정세기        13921 non-null  int64 \n",
      " 7   3번 감정          13921 non-null  object\n",
      " 8   3번 감정세기        13921 non-null  int64 \n",
      " 9   4번 감정          13921 non-null  object\n",
      " 10  4번감정세기         13921 non-null  int64 \n",
      " 11  5번 감정          13921 non-null  object\n",
      " 12  5번 감정세기        13921 non-null  int64 \n",
      " 13  나이             13921 non-null  int64 \n",
      " 14  성별             13921 non-null  object\n",
      " 15  source         13921 non-null  object\n",
      " 16  wav_path       13921 non-null  object\n",
      " 17  file_exist     13921 non-null  bool  \n",
      " 18  file_path      13921 non-null  object\n",
      "dtypes: bool(1), int64(6), object(12)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7d0ac8d-184f-4927-91c6-49f5e3ce4646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               count  ratio (%)\n",
      "final_emotion                  \n",
      "anger           8370      60.12\n",
      "happiness       2555      18.35\n",
      "neutral         1529      10.98\n",
      "sadness         1467      10.54\n"
     ]
    }
   ],
   "source": [
    "emotion_counts = df[\"final_emotion\"].value_counts()\n",
    "emotion_ratio = df[\"final_emotion\"].value_counts(normalize=True) * 100\n",
    "\n",
    "# 감정별 샘플 수와 비율 함께 출력\n",
    "emotion_summary = pd.DataFrame({\n",
    "    \"count\": emotion_counts,\n",
    "    \"ratio (%)\": emotion_ratio.round(2)\n",
    "})\n",
    "\n",
    "print(emotion_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "033e0f67-99e3-4203-afed-c1bd3b6e7873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wav_id</th>\n",
       "      <th>발화문</th>\n",
       "      <th>final_emotion</th>\n",
       "      <th>1번 감정</th>\n",
       "      <th>1번 감정세기</th>\n",
       "      <th>2번 감정</th>\n",
       "      <th>2번 감정세기</th>\n",
       "      <th>3번 감정</th>\n",
       "      <th>3번 감정세기</th>\n",
       "      <th>4번 감정</th>\n",
       "      <th>4번감정세기</th>\n",
       "      <th>5번 감정</th>\n",
       "      <th>5번 감정세기</th>\n",
       "      <th>나이</th>\n",
       "      <th>성별</th>\n",
       "      <th>source</th>\n",
       "      <th>wav_path</th>\n",
       "      <th>file_exist</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5e258fd1305bcf3ad153a6a4</td>\n",
       "      <td>어, 청소 니가 대신 해 줘!</td>\n",
       "      <td>anger</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>./4차년도</td>\n",
       "      <td>감정 분류를 위한 대화 음성 데이터셋\\./4차년도\\5e258fd1305bcf3ad1...</td>\n",
       "      <td>True</td>\n",
       "      <td>./감정 분류를 위한 대화 음성 데이터셋/4차년도\\5e258fd1305bcf3ad1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5e258fe2305bcf3ad153a6a5</td>\n",
       "      <td>둘 다 청소 하기 싫어. 귀찮아.</td>\n",
       "      <td>anger</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>./4차년도</td>\n",
       "      <td>감정 분류를 위한 대화 음성 데이터셋\\./4차년도\\5e258fe2305bcf3ad1...</td>\n",
       "      <td>True</td>\n",
       "      <td>./감정 분류를 위한 대화 음성 데이터셋/4차년도\\5e258fe2305bcf3ad1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5e258ff5305bcf3ad153a6a6</td>\n",
       "      <td>둘 다 하기 싫어서 화내.</td>\n",
       "      <td>anger</td>\n",
       "      <td>Angry</td>\n",
       "      <td>1</td>\n",
       "      <td>Angry</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "      <td>1</td>\n",
       "      <td>Angry</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>./4차년도</td>\n",
       "      <td>감정 분류를 위한 대화 음성 데이터셋\\./4차년도\\5e258ff5305bcf3ad1...</td>\n",
       "      <td>True</td>\n",
       "      <td>./감정 분류를 위한 대화 음성 데이터셋/4차년도\\5e258ff5305bcf3ad1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5e25902f305bcf3ad153a6a9</td>\n",
       "      <td>그럼 방세는 어떡해.</td>\n",
       "      <td>anger</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>1</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>1</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>1</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>1</td>\n",
       "      <td>Sadness</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>male</td>\n",
       "      <td>./4차년도</td>\n",
       "      <td>감정 분류를 위한 대화 음성 데이터셋\\./4차년도\\5e25902f305bcf3ad1...</td>\n",
       "      <td>True</td>\n",
       "      <td>./감정 분류를 위한 대화 음성 데이터셋/4차년도\\5e25902f305bcf3ad1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5e27fb575807b852d9e01595</td>\n",
       "      <td>어. 고등학교 동창인데 이렇게 더럽게 쓸줄 몰랐어.</td>\n",
       "      <td>anger</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>2</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>1</td>\n",
       "      <td>Angry</td>\n",
       "      <td>1</td>\n",
       "      <td>Disgust</td>\n",
       "      <td>2</td>\n",
       "      <td>Angry</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>./4차년도</td>\n",
       "      <td>감정 분류를 위한 대화 음성 데이터셋\\./4차년도\\5e27fb575807b852d9...</td>\n",
       "      <td>True</td>\n",
       "      <td>./감정 분류를 위한 대화 음성 데이터셋/4차년도\\5e27fb575807b852d9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     wav_id                           발화문 final_emotion  \\\n",
       "0  5e258fd1305bcf3ad153a6a4              어, 청소 니가 대신 해 줘!         anger   \n",
       "1  5e258fe2305bcf3ad153a6a5            둘 다 청소 하기 싫어. 귀찮아.         anger   \n",
       "2  5e258ff5305bcf3ad153a6a6                둘 다 하기 싫어서 화내.         anger   \n",
       "3  5e25902f305bcf3ad153a6a9                   그럼 방세는 어떡해.         anger   \n",
       "4  5e27fb575807b852d9e01595  어. 고등학교 동창인데 이렇게 더럽게 쓸줄 몰랐어.         anger   \n",
       "\n",
       "     1번 감정  1번 감정세기    2번 감정  2번 감정세기    3번 감정  3번 감정세기    4번 감정  4번감정세기  \\\n",
       "0  Neutral        0    Angry        1  Neutral        0  Neutral       0   \n",
       "1  Neutral        0    Angry        1  Neutral        0  Neutral       0   \n",
       "2    Angry        1    Angry        1  Neutral        0    Angry       1   \n",
       "3  Sadness        1  Sadness        1  Sadness        1  Sadness       1   \n",
       "4  Disgust        2  Disgust        1    Angry        1  Disgust       2   \n",
       "\n",
       "     5번 감정  5번 감정세기  나이    성별  source  \\\n",
       "0    Angry        1  27  male  ./4차년도   \n",
       "1    Angry        1  27  male  ./4차년도   \n",
       "2    Angry        1  27  male  ./4차년도   \n",
       "3  Sadness        1  27  male  ./4차년도   \n",
       "4    Angry        1  32  male  ./4차년도   \n",
       "\n",
       "                                            wav_path  file_exist  \\\n",
       "0  감정 분류를 위한 대화 음성 데이터셋\\./4차년도\\5e258fd1305bcf3ad1...        True   \n",
       "1  감정 분류를 위한 대화 음성 데이터셋\\./4차년도\\5e258fe2305bcf3ad1...        True   \n",
       "2  감정 분류를 위한 대화 음성 데이터셋\\./4차년도\\5e258ff5305bcf3ad1...        True   \n",
       "3  감정 분류를 위한 대화 음성 데이터셋\\./4차년도\\5e25902f305bcf3ad1...        True   \n",
       "4  감정 분류를 위한 대화 음성 데이터셋\\./4차년도\\5e27fb575807b852d9...        True   \n",
       "\n",
       "                                           file_path  \n",
       "0  ./감정 분류를 위한 대화 음성 데이터셋/4차년도\\5e258fd1305bcf3ad1...  \n",
       "1  ./감정 분류를 위한 대화 음성 데이터셋/4차년도\\5e258fe2305bcf3ad1...  \n",
       "2  ./감정 분류를 위한 대화 음성 데이터셋/4차년도\\5e258ff5305bcf3ad1...  \n",
       "3  ./감정 분류를 위한 대화 음성 데이터셋/4차년도\\5e25902f305bcf3ad1...  \n",
       "4  ./감정 분류를 위한 대화 음성 데이터셋/4차년도\\5e27fb575807b852d9...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "719c86dd-06c7-4624-a7e6-40892847ad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_audio(file_path):\n",
    "    waveform, sr = torchaudio.load(file_path)\n",
    "    if sr != 16000:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)\n",
    "        waveform = resampler(waveform)\n",
    "    return waveform.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65afaca9-f797-42ee-9f88-217398ce8d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embedding(wav_path):\n",
    "    try:\n",
    "        waveform = load_audio(wav_path)\n",
    "        inputs = processor(waveform, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs.to(device))\n",
    "        # [CLS] 벡터 대신 평균 사용\n",
    "        embedding = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "        return embedding\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 오류: {wav_path} — {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f30fa608-991c-481e-bf77-d7f64a6db673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13921/13921 [1:04:57<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 저장 완료: (13921, 768), 13921\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "labels = []\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    emb = extract_embedding(row[\"wav_path\"])\n",
    "    if emb is not None:\n",
    "        embeddings.append(emb)\n",
    "        labels.append(row[\"final_emotion\"])\n",
    "\n",
    "# numpy로 저장\n",
    "X = np.stack(embeddings)\n",
    "y = np.array(labels)\n",
    "\n",
    "np.save(\"emotion_X_excl_disgust.npy\", X)\n",
    "np.save(\"emotion_y_excl_disgust.npy\", y)\n",
    "\n",
    "print(f\"✅ 저장 완료: {X.shape}, {len(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f1cfc57d-84b7-45c9-aabf-14419bef2b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 사용자 임베딩 저장 완료: registered_user_embedding.npy\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "# 스테레오를 모노로 변환하여 저장\n",
    "stereo_path = \"./user_reference/user.wav\"\n",
    "mono_path = \"./user_reference/user_mono.wav\"\n",
    "\n",
    "y, sr = librosa.load(stereo_path, sr=16000, mono=True)\n",
    "sf.write(mono_path, y, sr)\n",
    "\n",
    "# 임베딩 추출 및 저장\n",
    "user_emb = extract_embedding(mono_path)\n",
    "np.save(\"registered_user_embedding.npy\", user_emb)\n",
    "print(\"✅ 사용자 임베딩 저장 완료: registered_user_embedding.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
